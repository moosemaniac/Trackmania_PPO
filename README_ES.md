# ğŸï¸ Agente de ConducciÃ³n AutÃ³noma con Aprendizaje por Refuerzo Profundo

[![Python](https://img.shields.io/badge/python-v3.8+-blue.svg)](https://www.python.org/downloads/)
[![PyTorch](https://img.shields.io/badge/PyTorch-v1.9+-red.svg)](https://pytorch.org/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![Horas Entrenamiento](https://img.shields.io/badge/Horas%20Entrenamiento-220+-green.svg)]()
[![Episodios](https://img.shields.io/badge/Episodios-5600+-brightgreen.svg)]()

> **ImplementaciÃ³n de Deep Reinforcement Learning para navegaciÃ³n autÃ³noma de vehÃ­culos en entornos dinÃ¡micos de carreras**

ğŸ“– **[English Version](README.md)** | **[VersiÃ³n en EspaÃ±ol](README_ES.md)**

### ğŸŒ Contexto del Proyecto
Este proyecto fue desarrollado como **Trabajo Final de Grado** en la **Universitat Oberta de Catalunya (UOC), EspaÃ±a**. La implementaciÃ³n y el cÃ³digo estÃ¡n escritos en espaÃ±ol, mientras que la documentaciÃ³n se proporciona en inglÃ©s para mayor accesibilidad internacional y presentaciÃ³n profesional.

## ğŸš€ Resumen del Proyecto

Este proyecto implementa un **agente de OptimizaciÃ³n de PolÃ­tica Proximal (PPO)** entrenado desde cero para navegar circuitos de carreras de forma autÃ³noma en Trackmania 2020. El agente aprende a tomar decisiones de conducciÃ³n en tiempo real utilizando datos de sensores LIDAR, logrando mejoras significativas de rendimiento a travÃ©s del aprendizaje por refuerzo profundo.

### ğŸ¯ Logros Principales
- **ğŸ“ˆ 625% de mejora en rendimiento** a lo largo de 5,600+ episodios de entrenamiento
- **ğŸ§  ImplementaciÃ³n personalizada de PPO** construida desde cero
- **ğŸ“Š OptimizaciÃ³n avanzada de polÃ­ticas** usando arquitectura actor-crÃ­tico
- **ğŸ NavegaciÃ³n autÃ³noma** en entornos complejos de carreras
- **ğŸ”¬ MetodologÃ­a experimental rigurosa** con validaciÃ³n estadÃ­stica

## ğŸ› ï¸ Arquitectura TÃ©cnica

### DiseÃ±o del Espacio de Estados (83 dimensiones)
- **Sensores LIDAR**: 4 marcos temporales Ã— 19 rayos = 76 mediciones de distancia
- **DinÃ¡mica del VehÃ­culo**: 1 caracterÃ­stica de velocidad
- **Historial de Acciones**: 6 caracterÃ­sticas (2 acciones previas Ã— 3 dimensiones)

### Espacio de Acciones (Control Continuo)
- **AceleraciÃ³n/Frenado**: [-1, 1] (acelerador adelante/atrÃ¡s)
- **Control de DirecciÃ³n**: [-1, 1] (Ã¡ngulo de ruedas izquierda/derecha)
- **Control Auxiliar**: [-1, 1] (control adicional del vehÃ­culo)

## ğŸ“Š MÃ©tricas de Rendimiento

| Fase de Entrenamiento | Recompensa Promedio | Longitud Episodio | Tasa de Ã‰xito | Mejoras Clave |
|----------------------|--------------------|--------------------|---------------|---------------|
| **Inicial** | 12,23 | ~500 pasos | <15% | ExploraciÃ³n aleatoria |
| **Medio Entrenamiento** | 17,83 | ~1000 pasos | ~40% | NavegaciÃ³n bÃ¡sica |
| **Final** | 87,17 | 2500 pasos | >85% | **ConducciÃ³n experta** |
| **Mejora Total** | **+625%** | **+400%** | **+467%** | **PolÃ­tica convergida** |

### EstadÃ­sticas de Entrenamiento
- **Episodios Totales**: 5,608
- **Pasos de Tiempo Totales**: 4,529,231
- **DuraciÃ³n del Entrenamiento**: 220 horas, 1 minuto, 22 segundos
- **Rendimiento MÃ¡ximo**: 111,35 de recompensa (Episodio 5503)
- **Convergencia**: Rendimiento estable en los Ãºltimos 200 episodios

### ValidaciÃ³n AcadÃ©mica
**Trabajo Final de Grado**: "Entrenamiento de un agente de aprendizaje por refuerzo en Trackmania"
- **InstituciÃ³n**: Universitat Oberta de Catalunya (UOC)
- **AÃ±o**: 2025
- **Programa**: Grado en IngenierÃ­a InformÃ¡tica - EspecializaciÃ³n en Inteligencia Artificial
- **Tutor**: Gabriel MoyÃ  Alcover
- **CalificaciÃ³n**: [9,3]

### Relevancia Industrial
Este proyecto demuestra habilidades directamente aplicables a:
- **VehÃ­culos AutÃ³nomos**: Toma de decisiones en tiempo real y planificaciÃ³n de rutas
- **RobÃ³tica**: Control continuo e integraciÃ³n de sensores
- **IA de Juegos**: Comportamiento de agente inteligente y sistemas en tiempo real
- **InvestigaciÃ³n en Machine Learning**: ImplementaciÃ³n avanzada de algoritmos RL

## ğŸ“š TecnologÃ­as y Habilidades Demostradas

### TecnologÃ­as Principales de IA/ML
- **Aprendizaje por Refuerzo Profundo** (PPO, Actor-CrÃ­tico, Gradientes de PolÃ­tica)
- **DiseÃ±o de Arquitectura de Redes Neuronales** (PyTorch, Implementaciones Personalizadas)
- **OptimizaciÃ³n de HiperparÃ¡metros** (Ajuste sistemÃ¡tico, AnÃ¡lisis de rendimiento)
- **VisiÃ³n Computacional** (Procesamiento LIDAR, RepresentaciÃ³n de estado)

### Excelencia en IngenierÃ­a de Software
- **ProgramaciÃ³n Orientada a Objetos** (Arquitectura limpia, Patrones de diseÃ±o)
- **OptimizaciÃ³n de Rendimiento** (AceleraciÃ³n GPU, Algoritmos eficientes)
- **Sistemas en Tiempo Real** (Toma de decisiones de baja latencia, IntegraciÃ³n de sistemas)

### Habilidades de InvestigaciÃ³n y AnÃ¡lisis
- **DiseÃ±o Experimental** (Pruebas de hipÃ³tesis, ValidaciÃ³n estadÃ­stica)
- **AnÃ¡lisis y VisualizaciÃ³n de Datos** (Matplotlib, MÃ©tricas estadÃ­sticas)
- **Escritura TÃ©cnica** (Trabajo Final de Grado, DocumentaciÃ³n clara)
- **ResoluciÃ³n de Problemas** (DepuraciÃ³n de algoritmos, OptimizaciÃ³n de rendimiento)

## ğŸ“– Referencias y Recursos

### ArtÃ­culos AcadÃ©micos Clave
- Schulman et al. (2017) - "Proximal Policy Optimization Algorithms"
- Haarnoja et al. (2018) - "Soft Actor-Critic: Off-Policy Maximum Entropy Deep RL"
- Sutton & Barto (2018) - "Reinforcement Learning: An Introduction"
- Lillicrap et al. (2015) - "Continuous Control with Deep Reinforcement Learning"

### Recursos TÃ©cnicos
- **Framework TMRL**: Proyecto comunitario Trackmania Reinforcement Learning
- **OpenPlanet**: Middleware de integraciÃ³n con Trackmania
- **DocumentaciÃ³n PyTorch**: Referencia del framework de deep learning
- **Gymnasium**: EstÃ¡ndar de entornos de aprendizaje por refuerzo

## ğŸ“„ Licencia

Este proyecto estÃ¡ licenciado bajo la Licencia MIT - ver el archivo [LICENSE](LICENSE) para detalles completos.

La Licencia MIT permite uso tanto acadÃ©mico como comercial, modificaciÃ³n y distribuciÃ³n.

## ğŸ‘¨â€ğŸ’» Autor

**Carlos ExpÃ³sito Carrera**
- ğŸ“ Graduado en IngenierÃ­a InformÃ¡tica, EspecializaciÃ³n en Inteligencia Artificial
- ğŸ« Universitat Oberta de Catalunya (UOC)
- ğŸ”¬ Enfoque de InvestigaciÃ³n: Deep Reinforcement Learning, Sistemas AutÃ³nomos
- ğŸ“§ Email: [cexposito1@gmail.com](mailto:cexposito1@gmail.com)
- ğŸ’¼ LinkedIn: [Carlos ExpÃ³sito Carrera](https://www.linkedin.com/in/carlos-exposito-carrera/)
- ğŸ™ GitHub: [@moosemaniac](https://github.com/moosemaniac)